{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxgP489jF9Ca"
   },
   "source": [
    "Valdes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ajguino7Gi-N"
   },
   "source": [
    "**Fouille du web et extraction d’informations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpXZDcJhGtjd"
   },
   "source": [
    "# Installation et paramétrisation des packages et librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 37465,
     "status": "ok",
     "timestamp": 1733490903488,
     "user": {
      "displayName": "Prince D. MEZUI R.",
      "userId": "15628813961743667758"
     },
     "user_tz": -60
    },
    "id": "I62w9tvQG0eP",
    "outputId": "5e3e58cc-91c1-40c0-f72e-4d42a6009b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting feedparser\n",
      "  Using cached feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting sgmllib3k (from feedparser)\n",
      "  Using cached sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Using cached feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (pyproject.toml): started\n",
      "  Building wheel for sgmllib3k (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6061 sha256=938cf09f3211c4aea9bf07008cc0f582bd2e37bce2a5717a47e9f6af419f8050\n",
      "  Stored in directory: c:\\users\\lenovo pc\\appdata\\local\\pip\\cache\\wheels\\03\\f5\\1a\\23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser\n",
      "Successfully installed feedparser-6.0.11 sgmllib3k-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install feedparser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4368,
     "status": "ok",
     "timestamp": 1733491209154,
     "user": {
      "displayName": "Prince D. MEZUI R.",
      "userId": "15628813961743667758"
     },
     "user_tz": -60
    },
    "id": "_TzZeghOIHvd",
    "outputId": "330bf30e-a684-4d08-8300-7902de5d62f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting newspaper3k\n",
      "  Using cached newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (4.12.3)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (10.4.0)\n",
      "Requirement already satisfied: PyYAML>=3.11 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (6.0.1)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: lxml>=3.6.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (5.3.0)\n",
      "Collecting nltk>=3.2.1 (from newspaper3k)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests>=2.10.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (2.32.3)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newspaper3k) (6.0.11)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
      "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
      "  Using cached feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
      "  Using cached jieba3k-0.35.1.zip (7.4 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\lenovo pc\\appdata\\roaming\\python\\python312\\site-packages (from newspaper3k) (2.9.0.post0)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
      "  Using cached tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.6)\n",
      "Requirement already satisfied: six in c:\\users\\lenovo pc\\appdata\\roaming\\python\\python312\\site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk>=3.2.1->newspaper3k)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2024.7.4)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
      "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (3.15.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk>=3.2.1->newspaper3k) (0.4.6)\n",
      "Using cached newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 7.2 MB/s eta 0:00:00\n",
      "Downloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k\n",
      "  Building wheel for tinysegmenter (pyproject.toml): started\n",
      "  Building wheel for tinysegmenter (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13568 sha256=98d5958498397a65d8f89aa9e81e2571508a790a175e2af0097519fe7308c912\n",
      "  Stored in directory: c:\\users\\lenovo pc\\appdata\\local\\pip\\cache\\wheels\\a5\\91\\9f\\00d66475960891a64867914273fcaf78df6cb04d905b104a2a\n",
      "  Building wheel for feedfinder2 (pyproject.toml): started\n",
      "  Building wheel for feedfinder2 (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3359 sha256=4d512a70004591c92b3e0e9519206bb08c8cb01961b40e625f97ae59dea3a7ec\n",
      "  Stored in directory: c:\\users\\lenovo pc\\appdata\\local\\pip\\cache\\wheels\\9f\\9f\\fb\\364871d7426d3cdd4d293dcf7e53d97f160c508b2ccf00cc79\n",
      "  Building wheel for jieba3k (pyproject.toml): started\n",
      "  Building wheel for jieba3k (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398385 sha256=83f101c1ae9781bf4ce7fbfedfcf54a7039aa78b5f9923fcc2c053dfbca458e2\n",
      "  Stored in directory: c:\\users\\lenovo pc\\appdata\\local\\pip\\cache\\wheels\\26\\72\\f7\\fff392a8d4ea988dea4ccf9788599d09462a7f5e51e04f8a92\n",
      "Successfully built tinysegmenter feedfinder2 jieba3k\n",
      "Installing collected packages: tinysegmenter, jieba3k, regex, cssselect, requests-file, nltk, feedfinder2, tldextract, newspaper3k\n",
      "Successfully installed cssselect-1.2.0 feedfinder2-0.0.4 jieba3k-0.35.1 newspaper3k-0.2.8 nltk-3.9.1 regex-2024.11.6 requests-file-2.1.0 tinysegmenter-0.3 tldextract-5.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 11549,
     "status": "ok",
     "timestamp": 1733491224291,
     "user": {
      "displayName": "Prince D. MEZUI R.",
      "userId": "15628813961743667758"
     },
     "user_tz": -60
    },
    "id": "06u2IjMVIIVH",
    "outputId": "44207e98-c8fa-4164-d15b-6f28c91488e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-md==3.8.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.8.0/fr_core_news_md-3.8.0-py3-none-any.whl (45.8 MB)\n",
      "     ---------------------------------------- 0.0/45.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 2.4/45.8 MB 12.2 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 5.5/45.8 MB 14.0 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 8.9/45.8 MB 14.6 MB/s eta 0:00:03\n",
      "     ---------- ---------------------------- 12.1/45.8 MB 14.8 MB/s eta 0:00:03\n",
      "     ------------ -------------------------- 14.9/45.8 MB 14.7 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 18.4/45.8 MB 14.8 MB/s eta 0:00:02\n",
      "     ------------------ -------------------- 21.2/45.8 MB 14.7 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 24.1/45.8 MB 14.7 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 25.7/45.8 MB 13.9 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 28.3/45.8 MB 13.8 MB/s eta 0:00:02\n",
      "     -------------------------- ------------ 30.9/45.8 MB 13.5 MB/s eta 0:00:02\n",
      "     ---------------------------- ---------- 33.6/45.8 MB 13.5 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 36.4/45.8 MB 13.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 38.8/45.8 MB 13.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 40.6/45.8 MB 13.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 43.3/45.8 MB 13.0 MB/s eta 0:00:01\n",
      "     --------------------------------------  45.6/45.8 MB 12.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  45.6/45.8 MB 12.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  45.6/45.8 MB 12.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  45.6/45.8 MB 12.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  45.6/45.8 MB 12.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  45.6/45.8 MB 12.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  45.6/45.8 MB 12.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 45.8/45.8 MB 9.5 MB/s eta 0:00:00\n",
      "Installing collected packages: fr-core-news-md\n",
      "Successfully installed fr-core-news-md-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "W7CqhdngSzuW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml_html_clean\n",
      "  Downloading lxml_html_clean-0.4.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lxml_html_clean) (5.3.0)\n",
      "Downloading lxml_html_clean-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: lxml_html_clean\n",
      "Successfully installed lxml_html_clean-0.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml_html_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3197,
     "status": "ok",
     "timestamp": 1733490911642,
     "user": {
      "displayName": "Prince D. MEZUI R.",
      "userId": "15628813961743667758"
     },
     "user_tz": -60
    },
    "id": "m4Ryn5bcFtP2",
    "outputId": "3190ad83-0cf6-47b5-c36c-c6d196c8dd6d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n",
      "'wget' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!wget https://people.irisa.fr/Guillaume.Gravier/teaching/ENSAI/data/francetvinfo.json\n",
    "!wget https://people.irisa.fr/Guillaume.Gravier/teaching/ENSAI/data/tvinfo-sources.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1733495163444,
     "user": {
      "displayName": "Prince D. MEZUI R.",
      "userId": "15628813961743667758"
     },
     "user_tz": -60
    },
    "id": "CX0jGahKHFa_"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import feedparser as fp\n",
    "import ssl\n",
    "import newspaper as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2Lis8QOHMwQ"
   },
   "source": [
    "# Importation des dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1733495616220,
     "user": {
      "displayName": "Prince D. MEZUI R.",
      "userId": "15628813961743667758"
     },
     "user_tz": -60
    },
    "id": "DoAkdMNfJRYc"
   },
   "outputs": [],
   "source": [
    "with open('francetvinfo.json', 'r') as f:\n",
    "  france_tv = json.load(f)\n",
    "\n",
    "with open('tvinfo-sources.json', 'r') as f:\n",
    "  src = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1761,
     "status": "ok",
     "timestamp": 1733495619096,
     "user": {
      "displayName": "Prince D. MEZUI R.",
      "userId": "15628813961743667758"
     },
     "user_tz": -60
    },
    "id": "KgMfU7GNLZez"
   },
   "outputs": [],
   "source": [
    "col = ['id'\n",
    ", 'title'\n",
    ", 'date'\n",
    ", 'content'\n",
    "       ]\n",
    "data_articles = pd.DataFrame(columns=col)\n",
    "\n",
    "for key, value in france_tv.items():\n",
    "  data_articles = pd.concat([data_articles,\n",
    "                             pd.DataFrame([[key\n",
    "                                            , value['title']\n",
    "                                            , value['date']\n",
    "                                            , value['content']\n",
    "                                            ]]\n",
    "                                          , columns=col)\n",
    "                             ],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6094,
     "status": "ok",
     "timestamp": 1733495639910,
     "user": {
      "displayName": "Prince D. MEZUI R.",
      "userId": "15628813961743667758"
     },
     "user_tz": -60
    },
    "id": "J3QNRDupVlae"
   },
   "outputs": [],
   "source": [
    "for key, value in src.items():\n",
    "  dt = fp.parse(value)\n",
    "\n",
    "  for item in dt.entries:\n",
    "    article = np.Article(item.link)\n",
    "    article.download()\n",
    "\n",
    "    data_articles = pd.concat([data_articles,\n",
    "                               pd.DataFrame([[value\n",
    "                                            , item.title\n",
    "                                            , item.published\n",
    "                                            , article.text\n",
    "                                            ]], columns=col)\n",
    "                               ], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOe9EuovBj3qLFfuJ0VrHeC",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
